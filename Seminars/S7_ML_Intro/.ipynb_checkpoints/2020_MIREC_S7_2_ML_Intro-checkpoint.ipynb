{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МИРЭК | 4 модуль\n",
    "\n",
    "*Автор: Татьяна Рогович*\n",
    "\n",
    "# Основы программирования в Python\n",
    "## Cеминар 7\n",
    "\n",
    "## Введение в ML. Задача регрессии. Решающее дерево и случайный лес\n",
    "\n",
    "Этот блокнот составлен на основе большого блокнота, который доступен по этой [ссылке](https://www.kaggle.com/dansbecker/your-first-machine-learning-model). В нем присутствуют дополнительные комментарии и другие примеры работы алгоритма. Если хотите как следует разобраться с деревьями на базовом уровне - обязательно читайте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем наши данные\n",
    "\n",
    "Нашим датасетом будет информация о домах, которая включает в себя множество параметров, например, количество и размер этажей дома, год постройки, общая площадь, цена и многое другое (остальные столбцы, можете изучить самостоятельно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Загружаем данные\n",
    "home_data = pd.read_csv('https://raw.githubusercontent.com/rogovich/2019-2020_PolSci_Data_Analysis_in_Python/master/12week_ML_Intro/house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор целевой переменной\n",
    "\n",
    "В нашем случае, все более-менее очевидно. Это цена на дом. Обычно, цель предсказания помечают y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = home_data.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор признаков (Features)\n",
    "\n",
    "Столбцы, которые есть в нашей модели и которые в последствии будут использованы для предсказания, называются признаками (features). В нашем случае, эти колонки будут определять стоимость дома. Иногда используются все колонки, кроме той на которую делается предсказание. А вдругих случаях, лучше выбрать только часть из них. Как определиться? Для этого проводят разведывательный анализ или сравнивают качество работы моделей на разных выборках признаков.\n",
    "\n",
    "Мы будет использовать не все столбцы, чтобы алгоритм все считал быстрее. Добавим в модель только те столбцы, которые сильнее всего коррелировали с ценой, когда мы исследовали данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['OverallQual', 'GrLivArea', 'GarageArea', 'TotalBsmtSF', 'FullBath', 'YearBuilt', 'YearRemodAdd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно, такие данные обозначаются X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = home_data[feature_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим модель\n",
    "\n",
    "Мы будем использовать модуль scikit-learn для создания модели. Scikit-learn одна из самых популярных библиотек для моделирования данных, хранящихся в датафреймах. \n",
    "\n",
    "Для построения модели нужно выполнить следующие шаги: <br>\n",
    "\n",
    "Define: Какого типа будет модель? Дерево решений? Какой-то другой тип?<br>\n",
    "Fit: запускаем модель на тренировочных данных (обучаем ее), чтобы алгоритм нашел в них некие закономерности и зависимости.<br>\n",
    "Predict: Предсказать результат.<br>\n",
    "Evaluate: Определить насколько точным оказалось предсказывание, оценить качество модели<br>\n",
    "\n",
    "В нашем примере, мы будет использовать дерево решений из scikit-learn и тренировать модель с признаками, выделенными ранее. Импортируем функцию DecisionTreeRegressort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель и обучим ее на наших данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициалазируем модель\n",
    "home_model = DecisionTreeRegressor()\n",
    "\n",
    "# Обучаем модель\n",
    "home_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам выше вывелась информация о нашем регрессоре и с какими парамтерами он обучался.\n",
    "\n",
    "Мы обучили модель. Но как хорошо она обучилась? Давайте предскажем значения и сравним их с теми ценами, которые на самом деле соответствуют домам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наше предсказание: [136000. 287090. 145000.  84500. 185000. 175000. 210000. 266500. 142125.\n",
      " 147500.]\n",
      "Реальная цена домов: [136000, 287090, 145000, 84500, 185000, 175000, 210000, 266500, 142125, 147500]\n"
     ]
    }
   ],
   "source": [
    "print(\"Наше предсказание:\", home_model.predict(X_train.tail(10)))\n",
    "print(\"Реальная цена домов:\", y_train.tail(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты похожи, но кое-где есть отличия. И мы отображаем всего 10 элементов из всей выборки. Посмотрим насколько правильно нам предсказала модель для всей выборки. Мы можем, конечно, пройтись в цикле по всем эелементам и посчитать ошибку у каждого. Но у нас могут быть как хорошие, так и плохие предсказания. И в идеальном случае нам нужна одна метрика, которая скажет как хорошо мы обучили данные.\n",
    "\n",
    "Воспульзуемся метрикой MEA (Mean Absolute Error) - Cредняя Aбсолютная Ошибка. Ее можно представить в таком виде: ошибка = реальная цена − предсказанная цена. Например, если цена дома 150 000, мы предсказали цены в 100 000, то ошибка будет 50 000. Для ошибок в отрицательную сторону берем модуль. Это одна из простейших метрик.\n",
    "\n",
    "Импортируем нужную функцию опять же из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказание и передаем в функцию предсказанное и реальное значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.4013698630137\n"
     ]
    }
   ],
   "source": [
    "pred = home_model.predict(X_train)\n",
    "mae = mean_absolute_error(pred, y_train)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили ошибку достаточно маленькую ошибку цены в долларах, что было бы очень хорошим результатом, если не одно но."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация данных\n",
    "\n",
    "Мы только что проверяли обученную модель на тех же данных, на которых мы ее и обучали. И это неверно. Т.к. в нашем случае нам нужно предсказывать цены новых домов, которых не было в обучающей выборке. Поэтому не удивительно, что MAE = 111. \n",
    "\n",
    "Опишем эту проблему таким примером. У нас есть большой рынок жилья. Цена жилья не связана с цветом входной двери. Но в нашей обучающей выборке у всех домов с высокой ценой была зеленая дверь. Модель увидит эту зависимость и будет предсказаывать для новых домов с зеленой дверью высокую цену, что не будет корректным. Но при валидации модели на обучающих данных мы получили маленькую ошибку и посчитали, что модель натренирована хорошо. Если бы мы это сделали на тестовых данных, то увидели бы что ошибка велика и нужно переделать модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающие и тестовые выборки\n",
    "\n",
    "Давайте разделим наши данные на 2 части: обучающую выборку и тестовую. Воспльзуемся опять модулем sklearn и функцией train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем данные как для X, так и для  y. Каждый раз разбитие происходит случайно, мы можем только указать в какой пропорции мы хотим разбить наши данные, например 30% всей выборки на обучение, остальное на тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполнили массивы с нашими данными \n",
    "X = home_data[feature_columns]\n",
    "y = home_data.SalePrice\n",
    "\n",
    "# Делим\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим сколько данных попала в обучающую и тестовые выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    }
   ],
   "source": [
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей 1095, а в тестовой 365 домов.\n",
    "\n",
    "Теперь как и в прошлый раз построим модель и посчитаем MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26924.701369863014\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем модель\n",
    "home_model = DecisionTreeRegressor()\n",
    "# Обучаем модель\n",
    "home_model.fit(train_X, train_y)\n",
    "\n",
    "# Предсказываем цены и считаем MAE\n",
    "val_predictions = home_model.predict(test_X)\n",
    "print(mean_absolute_error(test_y, val_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воу. Это большая ошибка по сравнению с нашей изначальной ошибкой на обучающей выборке. И выходит, что для новых домов, наша модель цены предсказывала бы плохо.\n",
    "\n",
    "Наша модель обучилась не очень оптимально, но к счастью есть несколько способов как можно улучшить модель, например, экспериментируя с параметрами модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперементируем с моделями\n",
    "\n",
    "Можно сказать что мы столкнулись с проблемой переобучения (overfitting), когда модель предсказывает обучающие данные практически идеально, а тестовые данные и другие данные предсказывате плохо.\n",
    "\n",
    "Существует еще и недообучение (underfitting), когда модель не может найти параметры по которым можно хорошо разделить данные, и она плохо предсказывает даже на обучающих данных.\n",
    "\n",
    "Так как мы используем DecisionTreeRegressor, т.е. дерево, в случае overfitting дерево обычно очень глубокое, а при underfitting получаем деревья небольшие. Поэтому мы может попробовать регулировать глубину дерева. В DecisionTreeRegressor есть параметер max_leaf_nodes, который мы можем контролировать. Чем больше листьев мы разрешим модели делать, тем дальше мы уйдем от underfiting, но будем приближаться к overfitting, т.е. в идеальном случае нам нужно подобрать примерно среднюю глубину дерева для модели.\n",
    "\n",
    "Создадим функцию, которая будет строить для нас деревеья с различным параметром max_leaf_nodes. А замерять модели будем снова через MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, test_X, train_y, test_y):\n",
    "    # инициализируем модель с параметром max_leaf_node, который мы передали в функцию\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes)\n",
    "    # обучаем модель на обучающих данных\n",
    "    model.fit(train_X, train_y)\n",
    "    # предсказываем на тестовых данных\n",
    "    preds_val = model.predict(test_X)\n",
    "    # считаем MAE\n",
    "    mae = mean_absolute_error(test_y, preds_val)\n",
    "    # возвращем значение ошибки\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В функцию мы соответственно передаем количество листов, которые мы хотим и обучающие и тестовые выборки. Сделаем небольшой цикл по различный значением глубины от 5 до 5000 и выведем результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная глубина дерева: 5  \t\t MEA:  35992\n",
      "Максимальная глубина дерева: 10  \t\t MEA:  30972\n",
      "Максимальная глубина дерева: 50  \t\t MEA:  26146\n",
      "Максимальная глубина дерева: 100  \t\t MEA:  26710\n",
      "Максимальная глубина дерева: 500  \t\t MEA:  27211\n",
      "Максимальная глубина дерева: 1000  \t\t MEA:  26554\n",
      "Максимальная глубина дерева: 5000  \t\t MEA:  26969\n"
     ]
    }
   ],
   "source": [
    "# сравниваем различне значения MAE для различной глубины деревьев\n",
    "for max_leaf_nodes in [5, 10, 50, 100, 500, 1000, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, test_X, train_y, test_y)\n",
    "    print(\"Максимальная глубина дерева: %d  \\t\\t MEA:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, самый лучший результат мы получили для глубины 100, но при этом ошибка достаточно большая и искажает предсказания для новых данных. С другой стороны, если мы посмотрим описательные статистики для нашей цены, мы увидим, что по сравнению со медианой и интерквартильным размахом, наша ошибка не настолько ужасна. Поэтому величина ошибки предсказания достаточно хитрая штука для интерпретации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1095.000000\n",
       "mean     181712.286758\n",
       "std       77955.082565\n",
       "min       34900.000000\n",
       "25%      130000.000000\n",
       "50%      165000.000000\n",
       "75%      215000.000000\n",
       "max      745000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Дерево решений оставляет с серьезным выбором. Глубокое дерево с overfitting с несколькими домами в каждом листе или мелкое дерево с несколькими листами, которое не может определить параметры и разделить данные? И все это с приличной ошибкой.\n",
    "\n",
    "Некоторые другие модели деревьев смогли решить эту проблему и уменьшить при этом итоговую ошибку. Попробуем взять Random Forest. Он использует множество деревьев и делает предсказание путем усреднения прогнозов каждого дерева.\n",
    "\n",
    "[Подробнее про случайный лес тут.](https://dyakonov.org/2016/11/14/%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D1%8B%D0%B9-%D0%BB%D0%B5%D1%81-random-forest/)\n",
    "\n",
    "Попробуем использовать Random Forest на наших данных. Импортируем его из модуля sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим теперь модель с тем же параметрами и данными как в DecissionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19441.526748858447\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем модель\n",
    "forest_model = RandomForestRegressor()\n",
    "# Обучаем модель\n",
    "forest_model.fit(train_X, train_y)\n",
    "# Делаем предсказание\n",
    "randomf_preds = forest_model.predict(test_X)\n",
    "# Посчитаем и выведем MAE\n",
    "print(mean_absolute_error(test_y, randomf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка уменьшилась, но все равно составляет больше 20 тысяч долларов. Можно продолжить дальше эксперементировать с моделью, изменяя параметры или увеличивая обучающую выборку. \n",
    "\n",
    "Давайте изменим параметр n_estimators, который отвечает за количество деревьев в модели ( не путать с количеством листьев в DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21662.834916046966\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем модель\n",
    "forest_model = RandomForestRegressor(n_estimators = 100)\n",
    "# Обучаем модель\n",
    "forest_model.fit(train_X, train_y)\n",
    "# Делаем предсказание\n",
    "randomf_preds = forest_model.predict(test_X)\n",
    "# Посчитаем и выведем MAE\n",
    "print(mean_absolute_error(test_y, randomf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже 19 тысяч! Много это или мало? Можно ли остановиться? \n",
    "\n",
    "Конечно, мы всегда стараемся минимизировать нашу ошибку, но это и не всегда возможно. Возможно, здесь лучше справится другая модель. Так же мы взяли очень мало признаков, при чем не основываясь на какой-то особой теории - возможно, преобразование наших признаков или же их замена, улучшили бы качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С остальными параметрами можно ознакомиться в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительным приятным бонусом использования моделей дерева и случайного леса является то, что мы можем использовать их определения важности признаков. Внутри себя дерево ранжируюет признаки на основании того, насколько разбиение по ним снижает неоднородность данных. Так мы можем использовать лес для отбора наиболее важных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OverallQual', 0.5767274638092772),\n",
       " ('GrLivArea', 0.1800254228003314),\n",
       " ('GarageArea', 0.057984302587197625),\n",
       " ('TotalBsmtSF', 0.09873909813622055),\n",
       " ('FullBath', 0.016522559961700576),\n",
       " ('YearBuilt', 0.03921901573357202),\n",
       " ('YearRemodAdd', 0.03078213697170065)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(feature_columns, forest_model.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.5767, 'OverallQual'), (0.18, 'GrLivArea'), (0.0987, 'TotalBsmtSF'), (0.058, 'GarageArea'), (0.0392, 'YearBuilt'), (0.0308, 'YearRemodAdd'), (0.0165, 'FullBath')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), forest_model.feature_importances_), feature_columns), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сравним с матрицей корреляции. Если бы мы ориентировались только на корреляции, мы считали два первых признака почти одинаково важным. По важностям, определенными решающим деревом видно, что 'OverallQual' с большим отрывом опережает площадь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverallQual     0.790982\n",
       "GrLivArea       0.708624\n",
       "GarageArea      0.623431\n",
       "TotalBsmtSF     0.613581\n",
       "FullBath        0.560664\n",
       "YearBuilt       0.522897\n",
       "YearRemodAdd    0.507101\n",
       "SalePrice       1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_data[feature_columns + ['SalePrice']].corr()['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На следующем семинаре мы вернемся к \"Титанику\" и попробуем, наконец, предсказать, кто же выжил во время крушения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
